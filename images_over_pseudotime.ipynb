{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tifffile as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import scipy.ndimage as ndi\n",
    "\n",
    "import skimage.measure as measure\n",
    "\n",
    "import line_utils\n",
    "import image_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish the path the Excel file\n",
    "base_path = \"/Users/zachcm/Documents/Projects/ExM_Nadja/01_Macros_Analysis/\"\n",
    "workbook = \"20241008_septin2_tubulin.xlsx\"\n",
    "workbook_path = os.path.join(base_path, workbook)\n",
    "expected_colnames=['Distance_(microns)', 'MTs', 'septin2', 'DAPI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the table of contents\n",
    "toc = pd.read_excel(workbook_path, sheet_name=\"ToC + P-t-p\", header=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load FWHM_along, which contains other statistics\n",
    "metrics = pd.read_excel(workbook_path, sheet_name=\"FWHM_along\", header=0).dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = line_utils.merge_df_information(toc, \n",
    "                                          metrics, \n",
    "                                          id_key=\"Label\", \n",
    "                                          mapped_keys=[\"dX (Âµm)\", \"dX (pxl)\", \"X1\", \"X2\", \"Angle\",\"X\",\"Y\",\"length\"])\n",
    "metrics = metrics[~metrics['Y'].isna()]\n",
    "# metrics = metrics.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's get the original images...\n",
    "import glob\n",
    "\n",
    "# ----- max proj files --- #\n",
    "# max_proj_path = \"/Volumes/Ries_Ewers/Septin2-GFP/MaxIPs\"\n",
    "# max_proj_files = glob.glob(max_proj_path+\"/*.tif\")\n",
    "\n",
    "# # ...and associate the file with each metrics entry\n",
    "# metrics[\"filename\"] = \"\"\n",
    "# for i, ml in metrics.iterrows():\n",
    "#     for fn in max_proj_files:\n",
    "#         if ml[\"Label\"] in fn:\n",
    "#             metrics.loc[i, \"filename\"] = fn\n",
    "#             break\n",
    "\n",
    "# ---- 3D files ---- #\n",
    "image_directory = \"/Volumes/Ries_Ewers/Septin2-GFP\"\n",
    "image_files = glob.glob(image_directory+\"/*.nd\")\n",
    "\n",
    "for i, ml in metrics.iterrows():\n",
    "    file_stub = os.path.splitext(ml[\"Label\"])[0]\n",
    "    for fn in image_files:\n",
    "        if file_stub in fn:\n",
    "            metrics.loc[i, \"filename\"] = fn\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = metrics.groupby('Unnamed: 0')\n",
    "\n",
    "plot_stack = None\n",
    "n_groups = len(groups)\n",
    "n_ch = 3\n",
    "length = 500\n",
    "l2 = length // 2\n",
    "group_img = np.zeros((n_groups, n_ch, length, length))\n",
    "metrics['dX2'] = np.nan\n",
    "metrics['X12'] = np.nan\n",
    "metrics['X22'] = np.nan\n",
    "for group, tup in enumerate(groups):\n",
    "    name, entries = tup\n",
    "    n_group = len(entries)\n",
    "    # mean_dX = entries['dX (pxl)'].mean()\n",
    "    im_proj = {}\n",
    "    for i, ml in entries.iterrows():\n",
    "        # Get the image associated with this row\n",
    "\n",
    "        # ---- If max proj -----\n",
    "        # im = tf.imread(ml[\"filename\"])\n",
    "        # ---- Elif mean proj ----\n",
    "        im = image_utils.NDImage(ml[\"filename\"])\n",
    "        im = im[:].mean(1).squeeze()\n",
    "        im_proj[i] = im\n",
    "        # --- End If ----\n",
    "\n",
    "        im = im/im.sum(-1).sum(-1)[:,None, None]\n",
    "\n",
    "\n",
    "        # get x, y, angle for this row\n",
    "        x, y, angle = ml[[\"X\", \"Y\", \"Angle\"]]\n",
    "\n",
    "        # Compute the line end points\n",
    "        xl, xu, yl, yu = line_utils.get_line_profile_endpoints(x, y, angle, length)\n",
    "\n",
    "        chs = measure.profile_line(im.T, \n",
    "                                [xl, yu], \n",
    "                                [xu, yl], \n",
    "                                linewidth=25)\n",
    "\n",
    "        mt, septin, dapi = chs.T\n",
    "\n",
    "        # --------- Fit septin peaks ---------\n",
    "\n",
    "        # Find peaks in the septin channel\n",
    "        peaks, peak_props, septin_threshold = line_utils.get_peaks(septin)\n",
    "        # weight the peaks by the MT channel signal\n",
    "        w, profile_center, sig = line_utils.compute_peak_weights(mt, peaks)\n",
    "        # Find the two peaks most likely to be septin rings\n",
    "        p0, p1 = line_utils.find_two_best_peaks(peaks, peak_props, septin_threshold, profile_center, w)\n",
    "        \n",
    "        # Get the distance between the peaks\n",
    "        dX2 = np.abs(p0-p1)\n",
    "\n",
    "        if (ml[\"Unnamed: 0\"] != \"A\") and (ml[\"Unnamed: 0\"] != \"BA\"):\n",
    "            metrics.loc[i,['X12','X22','dX2']] = [p0, p1, dX2]\n",
    "\n",
    "\n",
    "    mean_dX2 = entries['dX2'].mean()\n",
    "\n",
    "    for i, ml in entries.iterrows():\n",
    "        # Get the image associated with this row\n",
    "        # ---- If max proj -----\n",
    "        # im = tf.imread(ml[\"filename\"])\n",
    "        # ---- Elif mean proj ----\n",
    "        im = im_proj[i]\n",
    "        # --- End If ----\n",
    "        im = im/im.sum(-1).sum(-1)[:,None, None]\n",
    "\n",
    "        # get x, y, angle for this row\n",
    "        x, y, angle = ml[[\"X\", \"Y\", \"Angle\"]]\n",
    "\n",
    "        # Rotate the image  # CYX\n",
    "        im_rot = image_utils.pad_rot_and_trans_im(im, angle, x, y)\n",
    "\n",
    "        # Crop the image\n",
    "        xc, yc = im_rot.shape[2]//2, im_rot.shape[1]//2\n",
    "        im_crop = im_rot[:,(yc-length):(yc+length),(xc-length):(xc+length)]\n",
    "\n",
    "        # rescale the image\n",
    "        # if np.isnan(ml[\"dX (pxl)\"]):\n",
    "        if np.isnan(ml[\"dX2\"]):\n",
    "            im_zoom = im_crop\n",
    "        else:\n",
    "            # mag = ml[\"dX (pxl)\"]/mean_dX\n",
    "            mag = ml[\"dX2\"]/mean_dX2\n",
    "            im_zoom = ndi.zoom(im_crop, (1,1,mag))\n",
    "\n",
    "        # crop the image \n",
    "        xc, yc = im_zoom.shape[2]//2, im_crop.shape[1]//2\n",
    "        im_crop2 = im_zoom[:,(yc-l2):(yc+l2),(xc-l2):(xc+l2)]\n",
    "\n",
    "        # Get the rescaling to the septin endpoints\n",
    "        # xx_norm = line_utils.rescale_inds(length, int(ml[\"X1\"]), int(ml[\"X2\"]))\n",
    "        # xx_norm = mean_dX(2*xx_norm - 1)  # shift and scale\n",
    "\n",
    "        # crop it again\n",
    "        # if im_zoom.shape[2] > im_crop.shape[2]:\n",
    "        #     xc2, yc2 = im_zoom.shape[2]//2, im_zoom.shape[1]//2\n",
    "        #     im_crop2 = im_zoom[:,(yc2-l2):(yc2+l2),(xc2-l2):(xc2+l2)]\n",
    "        # elif im_zoom.shape[2] < im_crop.shape[2]:\n",
    "        #     im_crop2 = np.zeros((n_ch, length, length))\n",
    "        #     d2 = (length - im_zoom.shape[2])/2\n",
    "        #     if d2 == int(d2):\n",
    "        #         d2 = int(d2)\n",
    "        #         im_crop2[...,d2:-d2] = im_zoom\n",
    "        #     else:\n",
    "        #         d2 = int(d2)\n",
    "        #         im_crop2[...,d2:(-d2-1)] = im_zoom\n",
    "        group_img[group,...] += (im_crop2/n_group)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 4, 5, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "group_order = list(groups['Unnamed: 0'].unique().keys())\n",
    "true_order = [\"RC\", \"CS\", \"RS\", \"SM\", \"BA\", \"A\"]\n",
    "group_img_sorted = [group_order.index(g) for g in true_order]\n",
    "print(group_img_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.imwrite('pseudotime_images.ome.tif', group_img[group_img_sorted,...], metadata={'axes': 'TCYX'}, dtype=group_img.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "expansion",
   "language": "python",
   "name": "expansion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
