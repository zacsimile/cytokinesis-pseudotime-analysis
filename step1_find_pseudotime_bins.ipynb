{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import skimage.measure as measure\n",
    "\n",
    "import line_utils\n",
    "import image_utils\n",
    "import file_utils\n",
    "import pca_utils\n",
    "\n",
    "logger = logging.getLogger('pseudotime')\n",
    "logging.basicConfig(\n",
    "    filename='pseudotime_run.log',\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level=logging.DEBUG,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "# logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = file_utils.load_targets('targets.yaml')\n",
    "\n",
    "# Order of time stages\n",
    "time_key = \"Frame\"\n",
    "n_time_bins = 6\n",
    "\n",
    "# Channels per image (TODO: Auto detect)\n",
    "n_ch = 4\n",
    "\n",
    "# wavelengths to be found in the file names\n",
    "# Sublists are grouped. First element of the sublist is a group name.\n",
    "# NOTE: First element must be a number!\n",
    "wvls = [488,[568, \"orange\"],[646,647,657]]\n",
    "\n",
    "length = 500\n",
    "\n",
    "# pixel sizes (we assume they are constant)\n",
    "dx, dy, dz = 0.09, 0.09, 1\n",
    "\n",
    "# What features should we perform PCA on?\n",
    "\n",
    "features = [#\"diam_microtubule\", \n",
    "            \"diamM_micron\",\n",
    "            \"diamA_micron\",  \n",
    "            \"balance_microtubule\",\n",
    "            \"balance_septin3\",\n",
    "            \"delta_diam\",\n",
    "            \"ratio_diam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Go to each target's workbook and compute necessary additional metrics,\n",
    "# including distance between septin rings, septin ring diameter, and\n",
    "# microtubule bundle width.\n",
    "for k, v in targets.items():\n",
    "    try:\n",
    "        logger.debug(f\"Accessing {os.path.basename(v['workbook'])}\")\n",
    "    except KeyError:\n",
    "        # Not a target with a workbook\n",
    "        continue\n",
    "\n",
    "    # Pre-cleaned metrics\n",
    "    metrics = file_utils.load_workbooks({k: v})\n",
    "\n",
    "    # Establish columns for septin peak locations (x_septin_1, x_septin_2) and distance between them (dx_septin)\n",
    "    metrics['dx_septin'], metrics['x_septin_1'], metrics['x_septin_2'] = np.nan, np.nan, np.nan\n",
    "    metrics['diamA_micron'] = 0\n",
    "\n",
    "    # Establish empty columns for new metrics\n",
    "    metrics['diamM_micron'] = 0\n",
    "    metrics['delta_diam'] = 0\n",
    "    metrics['ratio_diam'] = 0\n",
    "   \n",
    "    for i, ml in metrics.iterrows():\n",
    "        logger.debug(f\"  Septin ring fit for {os.path.basename(ml['filename'])}\")\n",
    "\n",
    "        # Get the image associated with this row and load it with the channels sorted from high to low\n",
    "        im = image_utils.NDImage(ml[\"filename\"], load_sorted=True)\n",
    "\n",
    "        # get x, y, angle for this row\n",
    "        x, y, angle = ml[[\"X\", \"Y\", \"Angle\"]]\n",
    "\n",
    "        # find wavelengths in file name and sort from high to low\n",
    "        wvls_dict, binned_wvls = image_utils.extract_channel_targets_from_filename(ml[\"filename\"], wvls=wvls)\n",
    "\n",
    "        # Establish target names in this data set and sort from high to low to match image load\n",
    "        channel_targets = [wvls_dict[str(wvl)] for wvl in sorted(binned_wvls)[::-1]]\n",
    "\n",
    "        # the last channel is always DAPI, if unknown\n",
    "        if len(channel_targets) < n_ch:\n",
    "            channel_targets.append(\"DAPI\") \n",
    "\n",
    "        # --------- Fit septin peaks ---------\n",
    "\n",
    "        # ... get the septin peaks\n",
    "        mt_ch = [i for i, t in enumerate(channel_targets) if any([t == n for n in image_utils.target_names(targets, \"MTs\")])][0]\n",
    "        septin_ch = [i for i, t in enumerate(channel_targets) if any([t == n for n in image_utils.target_names(targets, \"septin\")])][0]\n",
    "        im_proj = im[:].mean(1).squeeze()\n",
    "        p0, p1, dX2 = line_utils.find_septin_peaks(im_proj, x, y, angle, length,\n",
    "                                                    mt_ch=mt_ch, \n",
    "                                                    septin_ch=septin_ch)\n",
    "\n",
    "        metrics.loc[i,['x_septin_1','x_septin_2','dx_septin']] = [p0, p1, dX2]\n",
    "\n",
    "        # --------- Get the number of occupied pixels in the MT profile ---------\n",
    "        # This is important for distinguishing abscission from others\n",
    "        xl, xu, yl, yu = line_utils.get_line_profile_endpoints(x, y, angle, length)\n",
    "\n",
    "        chs = measure.profile_line(im_proj, [xl, yu], [xu, yl], linewidth=25)\n",
    "\n",
    "        mt, septin = chs[:,mt_ch], chs[:,septin_ch]\n",
    "\n",
    "        mt_min, mt_max = np.min(mt), np.max(mt)\n",
    "        mt_norm = (mt-mt_min)/(mt_max-mt_min)\n",
    "        metrics.loc[i,'fill_microtubule'] = np.sum(mt_norm)/(length*25)\n",
    "\n",
    "        # --------- Get the ratio of one side of the MT profile to the other ---------\n",
    "        mt_mid = len(mt) // 2\n",
    "        half1, half2 = mt_norm[:mt_mid], mt_norm[mt_mid:][::-1]\n",
    "\n",
    "        # Demand the split be the same length (it should be, but in case it's odd line length)\n",
    "        if len(half1) != len(half2):\n",
    "            clipto = min(len(half1), len(half2))\n",
    "            half1 = half1[:clipto]\n",
    "            half2 = half2[:clipto]\n",
    "\n",
    "        half1s, half2s = half1.sum(), half2.sum()\n",
    "        metrics.loc[i,'balance_microtubule'] = min(half1s,half2s)/max(half1s,half2s)\n",
    "\n",
    "        # Always put the half with more signal in the denominator \n",
    "        if half1s <= half2s:\n",
    "            metrics.loc[i,'balance_microtubule2'] = np.nanmean(half1/(half2+1e-6))\n",
    "            metrics.loc[i,'balance_microtubule3'] = np.nanmean(half2/(half1+1e-6))\n",
    "        else:\n",
    "            metrics.loc[i,'balance_microtubule2'] = np.nanmean(half2/(half1+1e-6))\n",
    "            metrics.loc[i,'balance_microtubule3'] = np.nanmean(half1/(half2+1e-6))\n",
    "\n",
    "        # --------- Get the ratio of septin signal/mt signal ---------\n",
    "        sm_min = min(np.min(septin), np.min(mt))\n",
    "        sm_max = max(np.max(septin), np.max(mt))\n",
    "        septin_norm = (septin-sm_min)/(sm_max-sm_min)\n",
    "        septin_norm2 = (septin-mt_min)/(mt_max-mt_min)\n",
    "        mt_norm2 = (mt-sm_min)/(sm_max-sm_min)\n",
    "        metrics.loc[i,'balance_septin'] = np.mean(septin_norm/(mt_norm2+1e-6))\n",
    "        metrics.loc[i,'balance_septin2'] = np.mean(septin_norm**2/(mt_norm2+1e-6))\n",
    "        metrics.loc[i,'balance_septin3'] = np.mean(septin_norm2/(mt_norm+1e-6))\n",
    "        metrics.loc[i,'balance_septin4'] = np.mean(septin_norm2**2/(mt_norm+1e-6))\n",
    "\n",
    "        # --------- Fit septin rings ---------\n",
    "        p0x, p0y = line_utils.get_image_coordinate_from_distance_along_line(p0, xl, xu, yl, yu, len(septin))\n",
    "        p1x, p1y = line_utils.get_image_coordinate_from_distance_along_line(p1, xl, xu, yl, yu, len(septin))\n",
    "\n",
    "        # Now get the orthogonal line profile at the line center\n",
    "        xl3, xu3, yl3, yu3 = line_utils.get_line_profile_endpoints(p0x, p0y, angle-90, length)\n",
    "        chs = measure.profile_line(im_proj.T, [xl3, yu3], [xu3, yl3], linewidth=25)\n",
    "        septin_ring0 = chs[:,septin_ch]\n",
    "\n",
    "        ring0_diameter, res_lsq_ring0 = line_utils.fit_gaussian_fwhm(septin_ring0, return_dict=True)\n",
    "\n",
    "        # Now get the orthogonal line profile at the line center\n",
    "        xl4, xu4, yl4, yu4 = line_utils.get_line_profile_endpoints(p1x, p1y, angle-90, length)\n",
    "        chs = measure.profile_line(im_proj.T, [xl4, yu4], [xu4, yl4], linewidth=25)\n",
    "        septin_ring1 = chs[:,septin_ch]\n",
    "\n",
    "        ring1_diameter, _ = line_utils.fit_gaussian_fwhm(septin_ring1, return_dict=True)\n",
    "\n",
    "        metrics.loc[i,'diam_septin_ring'] = 0.5*(ring0_diameter + ring1_diameter)\n",
    "\n",
    "        # --------- Fit center MT cross-section ---------\n",
    "        # Now get the orthogonal line profile at the line center\n",
    "        xl2, xu2, yl2, yu2 = line_utils.get_line_profile_endpoints(x, y, angle-90, length)\n",
    "        chs = measure.profile_line(im_proj.T, [xl2, yu2], [xu2, yl2], linewidth=25)\n",
    "        mt = chs[:,mt_ch]\n",
    "\n",
    "        # Zach original\n",
    "        # outer_diameter, res_lsq = line_utils.fit_tubule_diameter(mt, return_dict=True)\n",
    "        # metrics.loc[i,'diam_microtubule'] = outer_diameter\n",
    "\n",
    "        # outer diameter modified for Expansion Factor 24.04.2025\n",
    "        try:\n",
    "            # outer_diameter, res_lsq = line_utils.fit_tubule_diameter(mt, return_dict=True)\n",
    "            outer_diameter, res_lsq = line_utils.fit_gaussian_fwhm(mt, return_dict=True)\n",
    "        except ValueError:\n",
    "            outer_diameter = 0\n",
    "        metrics.loc[i,'diam_microtubule'] = (outer_diameter) * (dx/metrics.loc[i,'EF'])\n",
    "\n",
    "        # Get diamA_micron\n",
    "        metrics.loc[i,'diamA_micron'] = (metrics.loc[i,'FWHM'] / 1000) * (dx/metrics.loc[i,'EF'])\n",
    "        \n",
    "        # --------- prepared from manually measured data 01.05.2025 ---------\n",
    "        \n",
    "\n",
    "        # Get diamM_micron\n",
    "        metrics.loc[i,'diamM_micron'] = (metrics.loc[i,'diamM'] / 1000) * (dx/metrics.loc[i,'EF'])\n",
    "\n",
    "        # Get delta_diam\n",
    "        metrics.loc[i,'delta_diam'] = ((metrics.loc[i,'diamM']) - (metrics.loc[i,'FWHM'])) / 1000 * (dx/metrics.loc[i,'EF'])\n",
    "\n",
    "        # Get ratio_diam\n",
    "        metrics.loc[i,'ratio_diam'] = (metrics.loc[i,'FWHM']) / (metrics.loc[i,'diamM'])\n",
    "\n",
    "      \n",
    "\n",
    "    # TODO: Should the behaviour be replace or new?\n",
    "    with pd.ExcelWriter(v['workbook'], mode=\"a\", engine=\"openpyxl\", if_sheet_exists=\"replace\") as writer:\n",
    "        metrics.to_excel(writer, sheet_name=f\"{v['workbook_sheet_name']}_processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's go grab the new calculations\n",
    "targets_processed = targets\n",
    "for k, v in targets.items():\n",
    "    try:\n",
    "        targets_processed[k][\"workbook_sheet_name\"] = f\"{v['workbook_sheet_name']}_processed\"\n",
    "        targets_processed[k][\"workbook_header_row\"] = 0\n",
    "    except KeyError:\n",
    "        continue\n",
    "\n",
    "# Load aggregated data from workbooks\n",
    "metrics = file_utils.load_workbooks(targets_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute PCA on the aggregated data and fit a polynomial through the space\n",
    "pca, coords, fit = pca_utils.pca(metrics[features], transform=True, fit=True)\n",
    "\n",
    "# Now add the PCA results as columns\n",
    "xx, yy = coords\n",
    "metrics[\"pca0\"] = xx\n",
    "metrics[\"pca1\"] = yy\n",
    "\n",
    "bins = pca_utils.sort_by_point_plane_dist(xx, yy, fit, nbins=n_time_bins)\n",
    "for i, bin in enumerate(bins):\n",
    "    # TODO: This only works because the merged metrics index matches the numerical index\n",
    "    # Be careful\n",
    "    metrics.loc[bins[i],time_key] = int(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display the PCA results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "\n",
    "stage_keys = {v:k for k,v in enumerate(metrics[\"Stage\"].unique())}\n",
    "# stage_colors = [stage_keys[x] for x in metrics[\"Stage\"]]\n",
    "\n",
    "\n",
    "\n",
    "colors = {'A':'#DDCC77', 'BA':'#999933', 'CS':'#88CCEE', 'RC':'#332288',  'RS':'#44AA99', 'SM':'#117733' }\n",
    "# colors = {'A':'#DDCC77', 'BA':'#999933', 'CS':'#FFFFFF', 'RC':'#FFFFFF',  'RS':'#44AA99', 'SM':'#117733' }\n",
    "\n",
    "colors_ls = [colors[x] for x in metrics[\"Stage\"]]\n",
    "\n",
    "scatter = ax.scatter(xx, yy, c=colors_ls, s=5, alpha=0.7)\n",
    "# scatter = ax.scatter(xx, yy, c=stage_colors, cmap='gist_rainbow_r', s=20)\n",
    "\n",
    "xxx = np.linspace(np.min(xx),np.max(xx),100)\n",
    "ax.plot(xxx, np.poly1d(fit)(xxx), linestyle='--', c='k')\n",
    "\n",
    "dist, xp, yp = pca_utils.point_poly_dist(xx, yy, fit)\n",
    "permutation = np.argsort(xp)\n",
    "\n",
    "# for i in range(len(xp)):\n",
    "#     ax.plot([xx[i], xp[i]], [yy[i], yp[i]], c='b', linewidth=0.5)\n",
    "\n",
    "ax.legend(scatter.legend_elements(num=len(stage_keys)-1)[0],list(stage_keys.keys()))\n",
    "ax.set_xlabel('PC0')\n",
    "ax.set_ylabel('PC1')\n",
    "# ax.set_xlim([-4,7])\n",
    "# ax.set_ylim([-2,14])\n",
    "\n",
    "#fig.savefig('20250508_pca_color_s5_opacity7_EF_adjusted_diamM_new_2.svg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the features ranked from most important (left) to least important (right)\n",
    "# per principle component (row number)\n",
    "pd.DataFrame({f\"feature{i}\": k for i, k in enumerate(np.array(features)[np.argsort(np.abs(pca.components_),axis=1)[:,::-1]].T)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now map the features back onto their original files\n",
    "for k, v in targets_processed.items():\n",
    "    try:\n",
    "        logger.debug(f\"Accessing {os.path.basename(v['workbook'])}\")\n",
    "    except KeyError:\n",
    "        # Not a target with a workbook\n",
    "        continue\n",
    "\n",
    "    # Pre-cleaned metrics\n",
    "    metrics_processed = file_utils.load_workbooks({k: v})\n",
    "\n",
    "    # Now merge in the PCA information\n",
    "    metrics_merged = pd.merge(metrics_processed, metrics, how=\"left\")\n",
    "\n",
    "    # And write to file\n",
    "    with pd.ExcelWriter(v['workbook'], mode=\"a\", engine=\"openpyxl\", if_sheet_exists=\"replace\") as writer:\n",
    "        metrics_merged.to_excel(writer, sheet_name=v['workbook_sheet_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "expansion",
   "language": "python",
   "name": "expansion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
