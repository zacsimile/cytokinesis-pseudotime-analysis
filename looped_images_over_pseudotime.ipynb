{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import glob\n",
    "import os\n",
    "from functools import reduce\n",
    "\n",
    "import tifffile as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import scipy.ndimage as ndi\n",
    "\n",
    "import line_utils\n",
    "import image_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = {}  # Start with an empty dictionary DO NOT DELETE\n",
    "\n",
    "# Describe all of our target proteins here\n",
    "# Any protein that does not have a specific workbook and image directory associated\n",
    "# will be considered a general marker, available across all workbooks\n",
    "targets[\"MTs\"] = {\"alias\": [\"aTub\", \"a-tub\", \"atub\", \"tub\", \"tub-m\", \"tub-rt\"]}\n",
    "\n",
    "targets[\"septin\"] = {\"alias\": [\"GFP\"]}\n",
    "\n",
    "targets[\"DAPI\"] = {}\n",
    "\n",
    "targets[\"MKLP1\"] = {\n",
    "    \"workbook\": \"/Volumes/Ries_Ewers/01_Macros_Analysis/MKLP1_along.xlsx\",\n",
    "    \"workbook_sheet_name\": \"ToC\",\n",
    "    \"workbook_header_row\": 4,\n",
    "    \"image_directory\": \"/Volumes/Ries_Ewers/MKLP1\",\n",
    "}\n",
    "\n",
    "targets[\"RacGAP1\"] = {\n",
    "    \"workbook\": \"/Volumes/Ries_Ewers/01_Macros_Analysis/RacGAP1_along.xlsx\",\n",
    "    \"workbook_sheet_name\": \"ToC\",\n",
    "    \"workbook_header_row\": 16,\n",
    "    \"image_directory\": \"/Volumes/Ries_Ewers/RacGAP1\",\n",
    "}\n",
    "\n",
    "targets[\"anillin\"] = {\n",
    "    \"workbook\": \"/Volumes/Ries_Ewers/01_Macros_Analysis/20241030_anillin_along.xlsx\",\n",
    "    \"workbook_sheet_name\": \"ToC\",\n",
    "    \"workbook_header_row\": 2,\n",
    "    \"image_directory\": \"/Volumes/Ries_Ewers/Anillin\",\n",
    "}\n",
    "\n",
    "targets[\"myoIIA\"] = {\n",
    "    \"workbook\": \"/Volumes/Ries_Ewers/01_Macros_Analysis/20241111_myosinIIA_along.xlsx\",\n",
    "    \"workbook_sheet_name\": \"ToC\",\n",
    "    \"workbook_header_row\": 0,\n",
    "    \"image_directory\": \"/Volumes/Ries_Ewers/Myosin IIA\",\n",
    "}\n",
    "\n",
    "targets[\"myoIIB\"] = {\n",
    "    \"workbook\": \"/Volumes/Ries_Ewers/01_Macros_Analysis/20241107_myoIIB_along.xlsx\",\n",
    "    \"workbook_sheet_name\": \"ToC\",\n",
    "    \"workbook_header_row\": 1,\n",
    "    \"image_directory\": \"/Volumes/Ries_Ewers/Myosin IIB\",\n",
    "    \"alias\": [\"mypoIIB\", \"myosinIIB\"]\n",
    "}\n",
    "\n",
    "targets[\"Cit-K\"] = {\n",
    "    \"workbook\": \"/Volumes/Ries_Ewers/01_Macros_Analysis/20241017_CitK_along.xlsx\",\n",
    "    \"workbook_sheet_name\": \"ToC\",\n",
    "    \"workbook_header_row\": 4,\n",
    "    \"image_directory\": \"/Volumes/Ries_Ewers/Citron Kinase\",\n",
    "}\n",
    "\n",
    "targets[\"CellMask\"] = {\n",
    "    \"workbook\": \"/Volumes/Ries_Ewers/01_Macros_Analysis/20241122_CellMasko_lineprofile.xlsx\",\n",
    "    \"workbook_sheet_name\": \"Tabelle1\",\n",
    "    \"workbook_header_row\": 1,\n",
    "    \"image_directory\": \"/Volumes/Ries_Ewers/CellMask Membrane\",\n",
    "}\n",
    "\n",
    "targets[\"PRC1\"] = {\n",
    "    \"workbook\": \"/Volumes/Ries_Ewers/01_Macros_Analysis/PRC1_along.xlsx\",\n",
    "    \"workbook_sheet_name\": \"ToC\",\n",
    "    \"workbook_header_row\": 1,\n",
    "    \"image_directory\": \"/Volumes/Ries_Ewers/PRC1\",\n",
    "}\n",
    "\n",
    "# Order of stages\n",
    "time_key = \"Stage\"\n",
    "time_order = [\"CF\", \"RC\", \"CS\", \"RS\", \"SM\", \"BA\", \"A\"]\n",
    "\n",
    "# Don't fit the septin ring locations at these time points\n",
    "time_do_not_fit = [\"BA\", \"A\"]\n",
    "\n",
    "# Channels per image (TODO: Auto detect)\n",
    "n_ch = 4\n",
    "\n",
    "# wavelengths to be found in the file names\n",
    "# Sublists are grouped. First element of the sublist is a group name.\n",
    "# NOTE: First element must be a number!\n",
    "wvls = [488,[568, \"orange\"],[646,647]]\n",
    "\n",
    "# desired channel order, specified by keys in targets\n",
    "desired_channel_order = [\"MTs\", \"septin\", \"DAPI\", \"MKLP1\", \"RacGAP1\", \"anillin\", \"myoIIA\", \"myoIIB\", \"Cit-K\", \"CellMask\", \"PRC1\"]\n",
    "desired_channel_order = [\"MTs\", \"septin\", \"DAPI\", \"MKLP1\", \"CellMask\"]\n",
    "\n",
    "# Length of cropped pseudotime region (should be roughly the line length)\n",
    "length = 500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we do anything, let's make sure all of our targets exist\n",
    "for key in desired_channel_order:\n",
    "    try:\n",
    "        targets[key] \n",
    "    except KeyError:\n",
    "        raise KeyError(f\"Element {key} does not exist in targets dictionary!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_names(targets, key):\n",
    "    \"\"\" \n",
    "    Construct a list of the key name plus any aliases. Important for searching\n",
    "    through file names.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        target = targets[key]\n",
    "    except KeyError:\n",
    "        return []\n",
    "    names = [key]\n",
    "    try:\n",
    "        names.extend(target[\"alias\"])\n",
    "    except KeyError:\n",
    "        pass\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the table of contents\n",
    "dfs = []\n",
    "for k, v in targets.items():\n",
    "    if k not in desired_channel_order:\n",
    "        continue\n",
    "    try:\n",
    "        df = pd.read_excel(v['workbook'], sheet_name=v['workbook_sheet_name'], header=v['workbook_header_row'])\n",
    "        df[\"target\"] = k\n",
    "        dfs.append(df)\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "metrics = reduce(lambda  left,right: pd.merge(left, right, how='outer'), dfs)\n",
    "\n",
    "# Get rid of rows with no line specified\n",
    "metrics = metrics[~metrics['Y'].isna()]\n",
    "\n",
    "# merge Length into length\n",
    "try:\n",
    "    mask = metrics['length'].isna()\n",
    "except KeyError:\n",
    "    # All our length columns are capitalized, which we do not expect\n",
    "    metrics.rename(columns={'Length': 'length'}, inplace=True)\n",
    "    mask = metrics['length'].isna()\n",
    "try:\n",
    "    metrics.loc[mask, 'length'] = metrics.loc[mask, 'Length']\n",
    "except KeyError:\n",
    "    # We didn't run into any cases with Length\n",
    "    pass\n",
    "\n",
    "# Drop unused columns\n",
    "metrics = metrics.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's find the original images...\n",
    "for group in metrics.groupby(\"target\"):\n",
    "    name, entries = group\n",
    "    image_files = glob.glob(targets[name][\"image_directory\"]+\"/*.nd\")\n",
    "    for i, ml in entries.iterrows():\n",
    "        file_stub = os.path.splitext(ml[\"Label\"])[0]\n",
    "        for fn in image_files:\n",
    "            if file_stub in fn:\n",
    "                metrics.loc[i, \"filename\"] = fn\n",
    "                break\n",
    "\n",
    "metrics = metrics[~metrics['filename'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: 35 averaged\n",
      "  CellMask: 21 averaged\n",
      "['tub-m', 'CellMask', 'GFP', 'DAPI'] [0, 2, 3, 1] [0, 1, 2, 4]\n",
      "['aTub', 'CellMask', 'GFP', 'DAPI'] [0, 2, 3, 1] [0, 1, 2, 4]\n",
      "['aTub', 'CellMask', 'GFP', 'DAPI'] [0, 2, 3, 1] [0, 1, 2, 4]\n",
      "['aTub', 'CellMask', 'GFP', 'DAPI'] [0, 2, 3, 1] [0, 1, 2, 4]\n",
      "['aTub', 'CellMask', 'GFP', 'DAPI'] [0, 2, 3, 1] [0, 1, 2, 4]\n",
      "['aTub', 'CellMask', 'GFP', 'DAPI'] [0, 2, 3, 1] [0, 1, 2, 4]\n",
      "['aTub', 'CellMask', 'GFP', 'DAPI'] [0, 2, 3, 1] [0, 1, 2, 4]\n",
      "['aTub', 'CellMask', 'GFP', 'DAPI'] [0, 2, 3, 1] [0, 1, 2, 4]\n",
      "['aTub', 'CellMask', 'GFP', 'DAPI'] [0, 2, 3, 1] [0, 1, 2, 4]\n",
      "['aTub', 'CellMask', 'GFP', 'DAPI'] [0, 2, 3, 1] [0, 1, 2, 4]\n",
      "['aTub', 'CellMask', 'GFP', 'DAPI'] [0, 2, 3, 1] [0, 1, 2, 4]\n",
      "['aTub', 'CellMask', 'GFP', 'DAPI'] [0, 2, 3, 1] [0, 1, 2, 4]\n",
      "['aTub', 'CellMask', 'GFP', 'DAPI'] [0, 2, 3, 1] [0, 1, 2, 4]\n",
      "['aTub', 'CellMask', 'GFP', 'DAPI'] [0, 2, 3, 1] [0, 1, 2, 4]\n",
      "['aTub', 'CellMask', 'GFP', 'DAPI'] [0, 2, 3, 1] [0, 1, 2, 4]\n",
      "['aTub', 'CellMask', 'GFP', 'DAPI'] [0, 2, 3, 1] [0, 1, 2, 4]\n",
      "['aTub', 'CellMask', 'GFP', 'DAPI'] [0, 2, 3, 1] [0, 1, 2, 4]\n",
      "['aTub', 'CellMask', 'GFP', 'DAPI'] [0, 2, 3, 1] [0, 1, 2, 4]\n",
      "['aTub', 'CellMask', 'GFP', 'DAPI'] [0, 2, 3, 1] [0, 1, 2, 4]\n",
      "['aTub', 'CellMask', 'GFP', 'DAPI'] [0, 2, 3, 1] [0, 1, 2, 4]\n",
      "['aTub', 'CellMask', 'GFP', 'DAPI'] [0, 2, 3, 1] [0, 1, 2, 4]\n",
      "  MKLP1: 14 averaged\n",
      "['MKLP1', 'MTs', 'GFP', 'DAPI'] [1, 2, 3, 0] [0, 1, 2, 3]\n",
      "['MKLP1', 'MTs', 'GFP', 'DAPI'] [1, 2, 3, 0] [0, 1, 2, 3]\n",
      "['MKLP1', 'MTs', 'GFP', 'DAPI'] [1, 2, 3, 0] [0, 1, 2, 3]\n",
      "['MKLP1', 'MTs', 'GFP', 'DAPI'] [1, 2, 3, 0] [0, 1, 2, 3]\n",
      "['a-tub', 'MKLP1', 'GFP', 'DAPI'] [0, 2, 3, 1] [0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "groups = metrics.groupby(time_key)\n",
    "\n",
    "plot_stack = None\n",
    "n_groups = len(groups)\n",
    "l2 = length // 2\n",
    "group_img = np.zeros((n_groups, len(desired_channel_order), length, length))\n",
    "\n",
    "# Establish columns for septin peaks (X12, X22) and distance between them (dX2)\n",
    "metrics['dX2'], metrics['X12'], metrics['X22'] = np.nan, np.nan, np.nan\n",
    "\n",
    "for group, tup in enumerate(groups):\n",
    "    name, entries = tup\n",
    "    n_group = len(entries)\n",
    "    print(f\"{name}: {n_group} averaged\")\n",
    "    im_proj = {}\n",
    "\n",
    "    # In a first pass, fit the septin ring distances for registration\n",
    "    for i, ml in entries.iterrows():\n",
    "        if ml[time_key] not in time_do_not_fit:\n",
    "            # If we are in a class where it makes sense...\n",
    "\n",
    "            # Get the image associated with this row and load it with the channels sorted from high to low\n",
    "            im = image_utils.NDImage(ml[\"filename\"], load_sorted=True)\n",
    "\n",
    "            # get x, y, angle for this row\n",
    "            x, y, angle = ml[[\"X\", \"Y\", \"Angle\"]]\n",
    "\n",
    "            # find wavelengths in file name and sort from high to low\n",
    "            wvls_dict, binned_wvls = image_utils.extract_channel_targets_from_filename(ml[\"filename\"], wvls=wvls)\n",
    "\n",
    "            # Establish target names in this data set and sort from high to low to match image load\n",
    "            channel_targets = [wvls_dict[str(wvl)] for wvl in sorted(binned_wvls)[::-1]]\n",
    "\n",
    "            # the last channel is always DAPI, if unknown\n",
    "            if len(channel_targets) < n_ch:\n",
    "                channel_targets.append(\"DAPI\") \n",
    "\n",
    "            # ... get the septin peaks\n",
    "            mt_ch = [i for i, t in enumerate(channel_targets) if any([t == n for n in target_names(targets, \"MTs\")])][0]\n",
    "            septin_ch = [i for i, t in enumerate(channel_targets) if any([t == n for n in target_names(targets, \"septin\")])][0]\n",
    "            p0, p1, dX2 = line_utils.find_septin_peaks(im[:].mean(1).squeeze(), x, y, angle, length,\n",
    "                                                        mt_ch=mt_ch, \n",
    "                                                        septin_ch=septin_ch)\n",
    "\n",
    "            metrics.loc[i,['X12','X22','dX2']] = [p0, p1, dX2]\n",
    "\n",
    "\n",
    "    # Now compute the average distance\n",
    "    mean_dX2 = entries['dX2'].mean()\n",
    "\n",
    "    # In our second pass, average these images\n",
    "    for t, tup2 in enumerate(entries.groupby(\"target\")):\n",
    "        name2, entries2 = tup2\n",
    "        n_target = len(entries2)\n",
    "        print(f\"  {name2}: {n_target} averaged\")\n",
    "        for i, ml in entries2.iterrows():\n",
    "            # Get the image associated with this row\n",
    "            im = image_utils.NDImage(ml[\"filename\"], load_sorted=True)\n",
    "\n",
    "            # find wavelengths in file name and sort from high to low\n",
    "            wvls_dict, binned_wvls = image_utils.extract_channel_targets_from_filename(ml[\"filename\"], wvls=wvls)\n",
    "\n",
    "            # Establish target names in this data set and sort from high to low to match image load\n",
    "            channel_targets = [wvls_dict[str(wvl)] for wvl in sorted(binned_wvls)[::-1]]\n",
    "\n",
    "            # the last channel is always DAPI, if unknown\n",
    "            if len(channel_targets) < n_ch:\n",
    "                channel_targets.append(\"DAPI\") \n",
    "\n",
    "            # Now find the resorting of the channels according to their target position\n",
    "            channel_order = []\n",
    "            group_channel_order = []\n",
    "            for j, ch in enumerate(desired_channel_order):\n",
    "                for opt in target_names(targets, ch):\n",
    "                    try:\n",
    "                        channel_order.append(channel_targets.index(opt))\n",
    "                        group_channel_order.append(j)\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "            assert len(channel_order) == n_ch #len(desired_channel_order)\n",
    "            print(channel_targets, channel_order, group_channel_order)\n",
    "\n",
    "            im = im[:].mean(1).squeeze()\n",
    "            \n",
    "            # Normalize\n",
    "            im = im/im.sum(-1).sum(-1)[:,None, None]\n",
    "            # im_min = im.min(-1).min(-1)\n",
    "            # im = (im - im_min[:,None,None])/((im.max(-1).max(-1)-im_min)[:,None,None])\n",
    "\n",
    "            # get x, y, angle for this row\n",
    "            x, y, angle = ml[[\"X\", \"Y\", \"Angle\"]]\n",
    "\n",
    "            # Rotate the image  # CYX\n",
    "            im_rot = image_utils.pad_rot_and_trans_im(im, angle, x, y)\n",
    "\n",
    "            # Crop the image\n",
    "            xc, yc = im_rot.shape[2]//2, im_rot.shape[1]//2\n",
    "            im_crop = im_rot[:,(yc-length):(yc+length),(xc-length):(xc+length)]\n",
    "\n",
    "            # rescale the image\n",
    "            # if np.isnan(ml[\"dX (pxl)\"]):\n",
    "            if np.isnan(ml[\"dX2\"]):\n",
    "                im_zoom = im_crop\n",
    "            else:\n",
    "                # mag = ml[\"dX (pxl)\"]/mean_dX\n",
    "                mag = ml[\"dX2\"]/mean_dX2\n",
    "                im_zoom = ndi.zoom(im_crop, (1,1,mag))\n",
    "\n",
    "            # Crop the image again\n",
    "            xc, yc = im_zoom.shape[2]//2, im_crop.shape[1]//2\n",
    "            im_crop2 = im_zoom[:,(yc-l2):(yc+l2),(xc-l2):(xc+l2)]\n",
    "\n",
    "            # Add the image with a weighting 1/length of the group \n",
    "            group_img[group,group_channel_order,...] += (im_crop2[channel_order]/np.array([n_group, n_group, n_group, n_target])[:,None,None])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 4, 5, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "group_order = list(groups[time_key].unique().keys())\n",
    "group_img_sorted = [group_order.index(g) for g in time_order if g in group_order]\n",
    "print(group_img_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_fn = f'pseudotime_images_{\"_\".join([x[0:2] for x in desired_channel_order])}.ome.tif'\n",
    "tf.imwrite(stack_fn, group_img[group_img_sorted,...], metadata={'axes': 'TCYX'}, dtype=group_img.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[7.13123569e-09, 7.24313277e-09, 6.96866360e-09, ...,\n",
       "         7.10562422e-09, 6.91126660e-09, 6.99687963e-09],\n",
       "        [6.96452706e-09, 7.10205180e-09, 6.97047700e-09, ...,\n",
       "         6.99935345e-09, 6.93691002e-09, 7.11215721e-09],\n",
       "        [6.96852160e-09, 7.20534047e-09, 7.11752182e-09, ...,\n",
       "         7.11691581e-09, 7.01636799e-09, 7.03660463e-09],\n",
       "        ...,\n",
       "        [7.32077148e-09, 7.35249304e-09, 7.49643714e-09, ...,\n",
       "         7.79079611e-09, 7.52650601e-09, 7.50484273e-09],\n",
       "        [7.32451801e-09, 7.27654106e-09, 7.56621178e-09, ...,\n",
       "         7.59895801e-09, 7.34884108e-09, 7.27754935e-09],\n",
       "        [7.38312655e-09, 7.24141460e-09, 7.40161163e-09, ...,\n",
       "         7.26759372e-09, 7.19460840e-09, 7.02623780e-09]],\n",
       "\n",
       "       [[7.15063760e-09, 7.38880265e-09, 7.24146510e-09, ...,\n",
       "         7.25436921e-09, 7.15400368e-09, 6.95993883e-09],\n",
       "        [7.17148459e-09, 7.35139979e-09, 7.22058379e-09, ...,\n",
       "         7.30142360e-09, 7.16977688e-09, 7.08551432e-09],\n",
       "        [7.15220647e-09, 7.41461790e-09, 7.27343059e-09, ...,\n",
       "         7.23174754e-09, 7.14319718e-09, 7.24617736e-09],\n",
       "        ...,\n",
       "        [7.79813679e-09, 7.88131112e-09, 7.94991500e-09, ...,\n",
       "         7.21307052e-09, 6.94578988e-09, 7.05911335e-09],\n",
       "        [7.89345767e-09, 7.83347606e-09, 7.91733196e-09, ...,\n",
       "         7.07460107e-09, 7.10163548e-09, 7.16973745e-09],\n",
       "        [7.70931325e-09, 7.69255732e-09, 7.75341463e-09, ...,\n",
       "         7.09371122e-09, 7.12890074e-09, 6.97506371e-09]],\n",
       "\n",
       "       [[8.75654082e-09, 8.89055155e-09, 8.90756561e-09, ...,\n",
       "         6.41009058e-09, 6.21492265e-09, 6.48059533e-09],\n",
       "        [8.75213675e-09, 8.87958218e-09, 8.68850212e-09, ...,\n",
       "         6.60957388e-09, 6.20941168e-09, 6.16308719e-09],\n",
       "        [8.91188516e-09, 8.93655101e-09, 8.86809357e-09, ...,\n",
       "         6.35386802e-09, 6.30403151e-09, 6.14454938e-09],\n",
       "        ...,\n",
       "        [7.98713522e-09, 7.89541135e-09, 7.99909451e-09, ...,\n",
       "         1.03337450e-08, 9.78052810e-09, 9.66616499e-09],\n",
       "        [7.89891311e-09, 8.03784166e-09, 7.88102065e-09, ...,\n",
       "         1.01953853e-08, 9.57926657e-09, 9.50273997e-09],\n",
       "        [7.94044325e-09, 8.06589559e-09, 8.01515336e-09, ...,\n",
       "         9.58466142e-09, 9.83177369e-09, 9.66091183e-09]],\n",
       "\n",
       "       [[1.23791955e-07, 1.26762042e-07, 1.22456330e-07, ...,\n",
       "         1.08450386e-07, 1.05689366e-07, 1.08291865e-07],\n",
       "        [1.21226195e-07, 1.26055533e-07, 1.24071198e-07, ...,\n",
       "         1.09341527e-07, 1.04235247e-07, 1.05180292e-07],\n",
       "        [1.23755459e-07, 1.22906080e-07, 1.24190609e-07, ...,\n",
       "         1.07776150e-07, 1.04756057e-07, 1.07338968e-07],\n",
       "        ...,\n",
       "        [1.17402695e-07, 1.24723197e-07, 1.24164584e-07, ...,\n",
       "         1.22594806e-07, 1.20869911e-07, 1.28020032e-07],\n",
       "        [1.22331701e-07, 1.23898165e-07, 1.26117288e-07, ...,\n",
       "         1.21939170e-07, 1.21854686e-07, 1.19888694e-07],\n",
       "        [1.23382856e-07, 1.19523346e-07, 1.26421315e-07, ...,\n",
       "         1.20355608e-07, 1.24667789e-07, 1.18854211e-07]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_crop2[channel_order]/np.array([n_group, n_group, n_group, 3])[:,None,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "expansion",
   "language": "python",
   "name": "expansion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
